{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv(\"test.csv\", on_bad_lines=\"skip\")\n",
    "\n",
    "# Extract product display names\n",
    "product_display_names = df['productDisplayName'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to tokenize and encode text\n",
    "def encode_text(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = tokens[:tokenizer.model_max_length - 2]  # Limiting to BERT's maximum input length\n",
    "    input_ids = tokenizer.encode(tokens, add_special_tokens=True)\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode product display names\n",
    "encoded_product_display_names = [encode_text(name) for name in product_display_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_product_display_names = model.encode(product_display_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode user query\n",
    "user_query = \"red shoes\"\n",
    "encoded_user_query = encode_text(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity\n",
    "similarities = []\n",
    "with torch.no_grad():\n",
    "    user_query_tensor = torch.tensor(encoded_user_query).unsqueeze(0)\n",
    "    user_query_embedding = model(user_query_tensor)[0][:, 0, :].numpy()  # Take the embedding of [CLS] token\n",
    "    for product_name in encoded_product_display_names:\n",
    "        product_tensor = torch.tensor(product_name).unsqueeze(0)\n",
    "        product_embedding = model(product_tensor)[0][:, 0, :].numpy()\n",
    "        similarity_score = cosine_similarity(user_query_embedding, product_embedding)[0][0]\n",
    "        print(similarity_score,end=\" \")\n",
    "        similarities.append(similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity\n",
    "similarities = cosine_similarity([encoded_user_query], encoded_product_display_names)[0]\n",
    "\n",
    "# Rank results\n",
    "k=5\n",
    "top_k_indices = similarities.argsort()[-k:][::-1]\n",
    "top_k_products = [product_display_names[index] for index in top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank results\n",
    "k=5\n",
    "similarity_scores_with_indices = list(enumerate(similarities))\n",
    "sorted_similarity_scores_with_indices = sorted(similarity_scores_with_indices, key=lambda x: x[1], reverse=True)\n",
    "top_k_indices = [index for index, _ in sorted_similarity_scores_with_indices[:k]]\n",
    "top_k_products = [product_display_names[index] for index in top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top k most similar products\n",
    "for i, product_name in enumerate(top_k_products):\n",
    "    print(f\"{i+1}. {product_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
